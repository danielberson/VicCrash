{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27f17c20-55fb-4a4e-a83a-4e4d53dd0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8488e0fc-9124-4df7-9d1f-8bb8d8cebee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('clean_crash_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5e3dbf-2358-460d-93e4-08205a7f4192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEVERITY\n",
       "3    413351\n",
       "2    195380\n",
       "1      9961\n",
       "4         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEVERITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3a56c3-128e-4f48-b151-739ee3f0d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEVERITY\n",
       "3    413351\n",
       "2    195380\n",
       "1      9961\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['SEVERITY'] != 4]\n",
    "df['SEVERITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079b55d-eefd-4b5b-b05b-393d40a051d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c3882f-93e1-4a31-8d6d-e1fca74150c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = df[['SEX', 'AGE', 'HELMET_BELT_WORN', 'DAY_OF_WEEK', 'LIGHT_CONDITION', 'ROAD_GEOMETRY', 'SPEED_ZONE', 'SURFACE_COND', 'TOTAL_NO_OCCUPANTS', 'VEHICLE_YEARS_OLD']]\n",
    "y = df['SEVERITY']\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_cols = ['SEX', 'HELMET_BELT_WORN', 'DAY_OF_WEEK', 'LIGHT_CONDITION', 'ROAD_GEOMETRY', 'SURFACE_COND']\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "feature_names = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=feature_names)\n",
    "# Drop the original categorical columns and concatenate the encoded columns\n",
    "X = pd.concat([X.drop(categorical_cols, axis=1).reset_index(drop=True), X_encoded_df.reset_index(drop=True)], axis=1)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# Create and train a logistic regression model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375761a0-327c-4164-8d37-65ab7cf6f25b",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0fc2b4-86a8-4213-9f93-26ff0b63a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6688432911208269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00      1992\n",
      "           2       0.48      0.08      0.14     39076\n",
      "           3       0.68      0.96      0.80     82671\n",
      "\n",
      "    accuracy                           0.67    123739\n",
      "   macro avg       0.39      0.35      0.31    123739\n",
      "weighted avg       0.60      0.67      0.58    123739\n",
      "\n",
      "[[    0   395  1597]\n",
      " [    0  3097 35979]\n",
      " [    0  3006 79665]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff88f12-774a-4f6f-80a1-6d3a0a42fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TOTAL_NO_OCCUPANTS', 0.19980381069988604),\n",
       " ('ROAD_GEOMETRY_2', 0.18015537657172717),\n",
       " ('LIGHT_CONDITION_5', 0.15459870200908976),\n",
       " ('HELMET_BELT_WORN_9', 0.11223333168352376),\n",
       " ('DAY_OF_WEEK_4', 0.10836398181598901),\n",
       " ('ROAD_GEOMETRY_5', 0.09893691887044134),\n",
       " ('LIGHT_CONDITION_3', 0.09769794623456836),\n",
       " ('SURFACE_COND_2', 0.0803667586414338),\n",
       " ('DAY_OF_WEEK_3', 0.07849514765027113),\n",
       " ('DAY_OF_WEEK_5', 0.07694751931554067),\n",
       " ('HELMET_BELT_WORN_2', 0.05060355793871352),\n",
       " ('SURFACE_COND_9', 0.05016217487868456),\n",
       " ('LIGHT_CONDITION_2', 0.049207573359401735),\n",
       " ('DAY_OF_WEEK_2', 0.048780507169666046),\n",
       " ('DAY_OF_WEEK_6', 0.042126081962104336),\n",
       " ('ROAD_GEOMETRY_4', 0.024163478869716884),\n",
       " ('LIGHT_CONDITION_9', 0.020603168367946557),\n",
       " ('VEHICLE_YEARS_OLD', 0.01704147374157583),\n",
       " ('AGE', 0.014804630781804398),\n",
       " ('DAY_OF_WEEK_1', 0.010395645482561569),\n",
       " ('LIGHT_CONDITION_6', 0.008689386289348872),\n",
       " ('SEX_M', 0.008022491670732048),\n",
       " ('SPEED_ZONE', 0.007534469824564507),\n",
       " ('HELMET_BELT_WORN_8', 0.007228747239744117),\n",
       " ('DAY_OF_WEEK_7', 0.005226184836453311),\n",
       " ('ROAD_GEOMETRY_3', 0.004557028898313482),\n",
       " ('SEX_U', 0.0027359357361716394),\n",
       " ('HELMET_BELT_WORN_7', 0.0024880998505667205),\n",
       " ('ROAD_GEOMETRY_9', 0.002391231413785313),\n",
       " ('SURFACE_COND_5', 0.001656009028953969),\n",
       " ('LIGHT_CONDITION_4', 0.0013163071222436647),\n",
       " ('HELMET_BELT_WORN_5', 0.0012942158889476924),\n",
       " ('SURFACE_COND_4', 0.0010914121789752918),\n",
       " ('HELMET_BELT_WORN_6', 0.0008604583294888283),\n",
       " ('SURFACE_COND_3', 0.0006187876807018364),\n",
       " ('ROAD_GEOMETRY_6', 0.000563238002780213),\n",
       " ('ROAD_GEOMETRY_8', 3.115465421544804e-05),\n",
       " ('ROAD_GEOMETRY_7', 2.249203922868694e-05),\n",
       " ('HELMET_BELT_WORN_4', 1.3778975864104891e-05)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = abs(model.coef_[0])  # Absolute values for importance\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0221ffcf-d83e-45ba-a2c0-99a51b530952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Severity Distribution:\n",
      "{1: 1992, 2: 39076, 3: 82671}\n",
      "\n",
      "Predicted Severity Distribution:\n",
      "{1: 958, 2: 30514, 3: 92267}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_actual, counts_actual = np.unique(y_test, return_counts=True)\n",
    "unique_predicted, counts_predicted = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "# Create dictionaries to store the counts\n",
    "actual_counts = dict(zip(unique_actual, counts_actual))\n",
    "predicted_counts = dict(zip(unique_predicted, counts_predicted))\n",
    "\n",
    "# Display the distribution of actual and predicted severities\n",
    "print(\"Actual Severity Distribution:\")\n",
    "print(actual_counts)\n",
    "\n",
    "print(\"\\nPredicted Severity Distribution:\")\n",
    "print(predicted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52e2d5-2169-4eae-992b-fae5c8008cb3",
   "metadata": {},
   "source": [
    "Baseline Logistic Regression Seems to underpredict class 1 quite heavily, try improve our model through HyperParameter tuning and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c1c459-5308-4cf5-8c75-e1579e30c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.33404073        nan 0.33780622        nan 0.33765731\n",
      "        nan 0.33808658        nan 0.33854595        nan 0.33648461]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10,\n",
       "                   class_weight={1: 20.703266825615927, 2: 1.055534940457911,\n",
       "                                 3: 0.4989244385307044})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10,\n",
       "                   class_weight={1: 20.703266825615927, 2: 1.055534940457911,\n",
       "                                 3: 0.4989244385307044})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10,\n",
       "                   class_weight={1: 20.703266825615927, 2: 1.055534940457911,\n",
       "                                 3: 0.4989244385307044})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = dict(zip([1, 2, 3], class_weight.compute_class_weight('balanced', classes=[1, 2, 3], y=y_train)))\n",
    "\n",
    "# Create and train a logistic regression model with class weights\n",
    "weighted_model = LogisticRegression(class_weight=class_weights)\n",
    "weighted_model.fit(X_train, y_train)\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2']  # Regularization type\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight=class_weights), param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = LogisticRegression(class_weight=class_weights, **best_params)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73daf86c-0b4b-40d1-a543-6f04b1a1534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.4595236748317022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.04      0.61      0.08      1992\n",
      "           2       0.35      0.30      0.32     39076\n",
      "           3       0.74      0.53      0.62     82671\n",
      "\n",
      "    accuracy                           0.46    123739\n",
      "   macro avg       0.37      0.48      0.34    123739\n",
      "weighted avg       0.60      0.46      0.52    123739\n",
      "\n",
      "[[ 1225   402   365]\n",
      " [11979 11679 15418]\n",
      " [17124 21590 43957]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c16ed4be-acec-4aa8-ba8d-567215fa6207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LIGHT_CONDITION_5', 0.8117292650506047),\n",
       " ('HELMET_BELT_WORN_2', 0.4630536853820863),\n",
       " ('DAY_OF_WEEK_4', 0.46171440564044175),\n",
       " ('SEX_M', 0.41242014626485857),\n",
       " ('SURFACE_COND_2', 0.37261681645378114),\n",
       " ('SURFACE_COND_9', 0.36070848448397147),\n",
       " ('DAY_OF_WEEK_3', 0.3157415637655155),\n",
       " ('DAY_OF_WEEK_5', 0.3034232638405772),\n",
       " ('HELMET_BELT_WORN_6', 0.2664049804989535),\n",
       " ('LIGHT_CONDITION_2', 0.22569072997420708),\n",
       " ('DAY_OF_WEEK_2', 0.21428324726674763),\n",
       " ('ROAD_GEOMETRY_4', 0.18104784336669003),\n",
       " ('LIGHT_CONDITION_9', 0.14587979484783808),\n",
       " ('ROAD_GEOMETRY_5', 0.13593550283350003),\n",
       " ('DAY_OF_WEEK_6', 0.1230298959445845),\n",
       " ('ROAD_GEOMETRY_2', 0.11045343681218386),\n",
       " ('LIGHT_CONDITION_3', 0.10171099555022661),\n",
       " ('HELMET_BELT_WORN_9', 0.1013538422430687),\n",
       " ('DAY_OF_WEEK_1', 0.09429158006375235),\n",
       " ('TOTAL_NO_OCCUPANTS', 0.07567882380314442),\n",
       " ('HELMET_BELT_WORN_7', 0.0646683261832012),\n",
       " ('LIGHT_CONDITION_6', 0.057676174726637594),\n",
       " ('ROAD_GEOMETRY_3', 0.04453533035421775),\n",
       " ('HELMET_BELT_WORN_8', 0.04164035045030494),\n",
       " ('SURFACE_COND_5', 0.03363369944193571),\n",
       " ('LIGHT_CONDITION_4', 0.028497003828565234),\n",
       " ('SURFACE_COND_3', 0.02817623060012358),\n",
       " ('ROAD_GEOMETRY_9', 0.02175506378156376),\n",
       " ('SPEED_ZONE', 0.018888676023271295),\n",
       " ('SEX_U', 0.011999697816197405),\n",
       " ('SURFACE_COND_4', 0.011067040397058645),\n",
       " ('HELMET_BELT_WORN_5', 0.006783859044888287),\n",
       " ('AGE', 0.003195548324989363),\n",
       " ('ROAD_GEOMETRY_6', 0.0024061916921539694),\n",
       " ('DAY_OF_WEEK_7', 0.0005499091582432288),\n",
       " ('ROAD_GEOMETRY_7', 0.0004961480901095034),\n",
       " ('VEHICLE_YEARS_OLD', 0.0001790266003392529),\n",
       " ('ROAD_GEOMETRY_8', 0.00011756704596241961),\n",
       " ('HELMET_BELT_WORN_4', 3.615424904223895e-05)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = abs(best_model.coef_[0])  # Absolute values for importance\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a659b8-c245-430c-82a0-ae8ef1dc9e9f",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee029e8c-b25a-480f-9b27-5aa08f5b7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define class weights (adjust as needed)\n",
    "class_weights = {1: 10, 2: 2, 3: 1}\n",
    "\n",
    "# Create the classifier with class weights\n",
    "clf = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa01dcf4-f0cf-40a6-a389-5067fce220bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "AGE: 0.3882\n",
      "VEHICLE_YEARS_OLD: 0.2735\n",
      "SPEED_ZONE: 0.0843\n",
      "TOTAL_NO_OCCUPANTS: 0.0457\n",
      "SURFACE_COND_2: 0.0205\n",
      "HELMET_BELT_WORN_9: 0.0144\n",
      "LIGHT_CONDITION_2: 0.0141\n",
      "ROAD_GEOMETRY_2: 0.0136\n",
      "ROAD_GEOMETRY_5: 0.0133\n",
      "SEX_M: 0.0111\n",
      "DAY_OF_WEEK_5: 0.0101\n",
      "DAY_OF_WEEK_6: 0.0100\n",
      "DAY_OF_WEEK_2: 0.0094\n",
      "DAY_OF_WEEK_3: 0.0092\n",
      "LIGHT_CONDITION_3: 0.0090\n",
      "DAY_OF_WEEK_4: 0.0090\n",
      "LIGHT_CONDITION_5: 0.0080\n",
      "DAY_OF_WEEK_1: 0.0078\n",
      "DAY_OF_WEEK_7: 0.0075\n",
      "SURFACE_COND_9: 0.0068\n",
      "HELMET_BELT_WORN_6: 0.0060\n",
      "ROAD_GEOMETRY_4: 0.0054\n",
      "HELMET_BELT_WORN_2: 0.0053\n",
      "LIGHT_CONDITION_6: 0.0023\n",
      "LIGHT_CONDITION_9: 0.0022\n",
      "HELMET_BELT_WORN_8: 0.0022\n",
      "HELMET_BELT_WORN_5: 0.0016\n",
      "LIGHT_CONDITION_4: 0.0015\n",
      "HELMET_BELT_WORN_7: 0.0015\n",
      "SURFACE_COND_5: 0.0015\n",
      "SURFACE_COND_3: 0.0013\n",
      "ROAD_GEOMETRY_3: 0.0012\n",
      "SEX_U: 0.0010\n",
      "ROAD_GEOMETRY_9: 0.0009\n",
      "SURFACE_COND_4: 0.0003\n",
      "ROAD_GEOMETRY_6: 0.0002\n",
      "ROAD_GEOMETRY_7: 0.0000\n",
      "ROAD_GEOMETRY_8: 0.0000\n",
      "HELMET_BELT_WORN_4: 0.0000\n",
      "\n",
      "Model Performance on Test Data:\n",
      "Accuracy: 0.6747\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.15      0.20      1992\n",
      "           2       0.50      0.39      0.44     39076\n",
      "           3       0.73      0.82      0.77     82671\n",
      "\n",
      "    accuracy                           0.67    123739\n",
      "   macro avg       0.51      0.45      0.47    123739\n",
      "weighted avg       0.66      0.67      0.66    123739\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  291   628  1073]\n",
      " [  270 15430 23376]\n",
      " [  409 14499 67763]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nModel Performance on Test Data:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d50fbb-30f7-4a55-bc39-dd0869daf0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define the hyperparameter grid for the Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(class_weight='balanced', random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03821f-aadf-4d8e-b807-2505afaefb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394811cb-92a6-407d-8ac9-1f595f9897dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Map class labels to start from 0\n",
    "y_train_mapped = y_train - 1  # Subtract 1 from each class label to map to 0, 1, 2\n",
    "y_test_mapped = y_test - 1\n",
    "\n",
    "# Calculate class weights for balanced classes\n",
    "class_weights = len(y_train_mapped) / (len(np.unique(y_train_mapped)) * np.bincount(y_train_mapped))\n",
    "\n",
    "# Create a custom weight array for each sample in the training data\n",
    "sample_weights = np.array([class_weights[label] for label in y_train_mapped])\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for the XGBoost model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to your data, passing the custom sample weights\n",
    "grid_search.fit(X_train, y_train_mapped, sample_weight=sample_weights)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = xgb.XGBClassifier(random_state=42, **best_params)\n",
    "\n",
    "# Fit the model using the custom sample weights\n",
    "best_model.fit(X_train, y_train_mapped, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Map predicted class labels back to 1, 2, 3\n",
    "y_pred_best_mapped = y_pred_best + 1\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best_mapped)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best_mapped))\n",
    "print(confusion_matrix(y_test, y_pred_best_mapped))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
