{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f17c20-55fb-4a4e-a83a-4e4d53dd0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488e0fc-9124-4df7-9d1f-8bb8d8cebee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('clean_crash_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e3dbf-2358-460d-93e4-08205a7f4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEVERITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a56c3-128e-4f48-b151-739ee3f0d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SEVERITY'] != 4]\n",
    "df['SEVERITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3882f-93e1-4a31-8d6d-e1fca74150c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['SEX', 'AGE', 'HELMET_BELT_WORN', 'DAY_OF_WEEK', 'LIGHT_CONDITION', 'ROAD_GEOMETRY', 'SPEED_ZONE', 'SURFACE_COND', 'TOTAL_NO_OCCUPANTS', 'VEHICLE_YEARS_OLD']]\n",
    "y = df['SEVERITY']\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_cols = ['SEX', 'HELMET_BELT_WORN', 'DAY_OF_WEEK', 'LIGHT_CONDITION', 'ROAD_GEOMETRY', 'SURFACE_COND']\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "feature_names = encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=feature_names)\n",
    "# Drop the original categorical columns and concatenate the encoded columns\n",
    "X = pd.concat([X.drop(categorical_cols, axis=1).reset_index(drop=True), X_encoded_df.reset_index(drop=True)], axis=1)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# Create and train a logistic regression model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d59c3f-7d54-400c-b3a5-04ff5ab5455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375761a0-327c-4164-8d37-65ab7cf6f25b",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fc2b4-86a8-4213-9f93-26ff0b63a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff88f12-774a-4f6f-80a1-6d3a0a42fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = abs(model.coef_[0])  # Absolute values for importance\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221ffcf-d83e-45ba-a2c0-99a51b530952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_actual, counts_actual = np.unique(y_test, return_counts=True)\n",
    "unique_predicted, counts_predicted = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "# Create dictionaries to store the counts\n",
    "actual_counts = dict(zip(unique_actual, counts_actual))\n",
    "predicted_counts = dict(zip(unique_predicted, counts_predicted))\n",
    "\n",
    "# Display the distribution of actual and predicted severities\n",
    "print(\"Actual Severity Distribution:\")\n",
    "print(actual_counts)\n",
    "\n",
    "print(\"\\nPredicted Severity Distribution:\")\n",
    "print(predicted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52e2d5-2169-4eae-992b-fae5c8008cb3",
   "metadata": {},
   "source": [
    "Baseline Logistic Regression Seems to underpredict class 1 quite heavily, try improve our model through HyperParameter tuning and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1c459-5308-4cf5-8c75-e1579e30c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(zip([1, 2, 3], class_weight.compute_class_weight('balanced', classes=[1, 2, 3], y=y_train)))\n",
    "\n",
    "# Create and train a logistic regression model with class weights\n",
    "weighted_model = LogisticRegression(class_weight=class_weights)\n",
    "weighted_model.fit(X_train, y_train)\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2']  # Regularization type\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight=class_weights), param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = LogisticRegression(class_weight=class_weights, **best_params)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daf86c-0b4b-40d1-a543-6f04b1a1534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ed4be-acec-4aa8-ba8d-567215fa6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = abs(best_model.coef_[0])  # Absolute values for importance\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a659b8-c245-430c-82a0-ae8ef1dc9e9f",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa709c6a-0c2d-4700-aa68-057016ae1586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e2754-22ac-4a1e-add1-1bb5ec82d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define class weights (adjust as needed)\n",
    "\n",
    "\n",
    "# Create the classifier with class weights\n",
    "clf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc0b09-a3ae-4d2f-86e5-7916f2e06dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nModel Performance on Test Data:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d50fbb-30f7-4a55-bc39-dd0869daf0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define the hyperparameter grid for the Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(class_weight='balanced', random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "# Get feature importance scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684baba-7138-4731-ab8b-3491cad4b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# Map feature names to importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features_rf_grid = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_features_rf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03821f-aadf-4d8e-b807-2505afaefb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394811cb-92a6-407d-8ac9-1f595f9897dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Map class labels to start from 0\n",
    "y_train_mapped = y_train - 1  # Subtract 1 from each class label to map to 0, 1, 2\n",
    "y_test_mapped = y_test - 1\n",
    "\n",
    "# Calculate class weights for balanced classes\n",
    "class_weights = len(y_train_mapped) / (len(np.unique(y_train_mapped)) * np.bincount(y_train_mapped))\n",
    "\n",
    "# Create a custom weight array for each sample in the training data\n",
    "sample_weights = np.array([class_weights[label] for label in y_train_mapped])\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for the XGBoost model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to your data, passing the custom sample weights\n",
    "grid_search.fit(X_train, y_train_mapped, sample_weight=sample_weights)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = xgb.XGBClassifier(random_state=42, **best_params)\n",
    "\n",
    "# Fit the model using the custom sample weights\n",
    "best_model.fit(X_train, y_train_mapped, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Map predicted class labels back to 1, 2, 3\n",
    "y_pred_best_mapped = y_pred_best + 1\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best_mapped)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(classification_report(y_test, y_pred_best_mapped))\n",
    "print(confusion_matrix(y_test, y_pred_best_mapped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8e2bc-8d63-40a7-a86b-cdd2173ab665",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# Create a list or a DataFrame to associate feature names with importance scores\n",
    "feature_names = X_train.columns  # Replace with your feature names\n",
    "feature_importance_list = list(zip(feature_names, feature_importance))\n",
    "\n",
    "# Sort the features by importance (optional)\n",
    "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the list of feature importance\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in feature_importance_list:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3dc6f-088c-4815-9847-66b09bd2e078",
   "metadata": {},
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301a0ac-64d7-48af-b21b-0598f7814526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define the hyperparameter grid for the SVC with 'rbf' kernel and a specific gamma value\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 5],\n",
    "    'kernel': ['rbf'],\n",
    "}\n",
    "\n",
    "# Create an SVC classifier\n",
    "svc = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_svc = GridSearchCV(svc, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_svc = grid_search_svc.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_svc_model = SVC(class_weight='balanced', random_state=42, **best_params_svc)\n",
    "best_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_svc = best_svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate The best SVC model\n",
    "accuracy_best_svc = accuracy_score(y_test, y_pred_best_svc)\n",
    "print(f'Best SVC Model Accuracy: {accuracy_best_svc}')\n",
    "print(classification_report(y_test, y_pred_best_svc))\n",
    "print(confusion_matrix(y_test, y_pred_best_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c04c4c-0743-4f5c-bec6-4ffda42978ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de63af-6a6a-4dd2-8f8b-d1eec2a86726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa087f4-9827-4487-83e0-71368349c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['DAY_OF_WEEK']==6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
